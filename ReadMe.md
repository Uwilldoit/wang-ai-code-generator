# AI零代码应用生成平台

## 一、用户模块

### 1、需求分析

对于用户模块，通常要具有下列功能：

- 用户注册
- 用户登录
- 用户注销
- 获取当前登录用户
- 用户权限控制
- 【管理员】管理用户

具体分析每个需求：

1. 用户注册：用户可以通过输入账号、密码、确认密码进行注册
2. 用户登录：用户可以通过输入账号和密码登录
3. 用户注销：用户可以退出登录
4. 获取当前登录用户：得到当前已经登录的用户信息（不用重复登录）
5. 用户权限控制：用户又分为普通用户和管理员，管理员拥有整个系统的最高权限，比如管理其他用户。后续可用考虑加入vip用户等。
6. 用户管理：仅管理员可用，可用对整个系统中的用户进行管理，比如搜索用户、删除用户



### 2、方案设计

- 库表设计
- 用户登录流程
- 如何对用户权限进行控制



#### 库表设计

库名：wang_ai_code_generator

表名：user（用户表）

##### 1、核心设计

用户表的核心是用户登录凭证（账号密码）和个人信息，SQL如下：

```sql
-- 用户表
create table if not exists user
(
    id           bigint auto_increment comment 'id' primary key,
    userAccount  varchar(256)                           not null comment '账号',
    userPassword varchar(512)                           not null comment '密码',
    userName     varchar(256)                           null comment '用户昵称',
    userAvatar   varchar(1024)                          null comment '用户头像',
    userProfile  varchar(512)                           null comment '用户简介',
    userRole     varchar(256) default 'user'            not null comment '用户角色：user/admin',
    editTime     datetime     default CURRENT_TIMESTAMP not null comment '编辑时间',
    createTime   datetime     default CURRENT_TIMESTAMP not null comment '创建时间',
    updateTime   datetime     default CURRENT_TIMESTAMP not null on update CURRENT_TIMESTAMP comment '更新时间',
    isDelete     tinyint      default 0                 not null comment '是否删除',
    UNIQUE KEY uk_userAccount (userAccount),
    INDEX idx_userName (userName)
) comment '用户' collate = utf8mb4_unicode_ci;

```

说明：

1、editTime和updateTime的区别：editTime表示用户编辑个人信息的时间（需要业务代码来更新），而updateTime表示这条用户记录任何字段发生修改的时间（由数据库自动更新）。

2、给唯一值添加唯一键(唯一索引)，比如账号 userAccount,利用数据库天然防重复，同时可以增加查询效率。

3、给经常用于查询的字段添加索引，比如用户昵称 userName,可以增加查询效率。

##### 2、扩展设计

1)如果要实现会员功能，可以对表进行如下扩展:

1.给 userRole 字段新增枚举值 vip ，表示会员用户，可根据该值判断用户权限

2.新增会员过期时间字段，可用于记录会员有效期

3.新增会员兑换码字段，可用于记录会员的开通方式

4.新增会员编号字段，可便于定位用户并提供额外服务，并增加会员归属感

增加的SQL

```sql
vipExpireTime datetime     null comment '会员过期时间',
vipCode       varchar(128) null comment '会员兑换码',
vipNumber     bigint       null comment '会员编号'
```

2)如果要实现用户邀请功能，可以对表进行如下扩展:

1.新增 shareCode 分享码字段，用于记录每个用户的唯一邀请标识，可拼接到邀请网址后面，比如 https://mianshiya.com/?shareCode=xxx

2.新增 inviteUser 字段，用于记录该用户被哪个用户邀请了，可通过这个字段查询某用户邀请的用户列表。

对应的SQL如下

```sql
shareCode     varchar(20)  DEFAULT NULL COMMENT '分享码',
inviteUser    bigint       DEFAULT NULL COMMENT '邀请用户 id'
```



#### 用户登录流程

1. 建立初始会话
2. 登录成功，更新会话信息
3. 前端保存Cookie
4. 带Cookie的后续请求
5. 后端验证会话
6. 获取会话中存储的信息





## 二、AI生成应用

### 实现AI应用生成（原生模式）

### SSE流式输出

LangChain4j + Reactor



#### 门面模式

为了统一管理生成和保存的逻辑，我决定使用门面模式这一设计模式。门面模式通过提供一个统一的高层接口来隐藏子系统的复杂性，让客户端只需要与这个简化的接口交互，而不需要了解内部的复杂实现细节。



### 代码优化：

在开发中，发现有大量重复代码，仔细分析后，决定使用以下优化策略：

- 解析器部分： 使用**策略模式**，不同类型的解析策略独立维护（**难点是不同解析策略的返回值不同**）
- 文件保存部分：使用**模板方法模式**，统一保存流程（**难点是不同保存方式的方法参数不同**）
- SSE流式处理部分：抽象出通用的流式处理逻辑（目前每种生成模式都写了 一套处理代码）

#### 策略模式（待补图）

策略模式定义了一系列算法，将每个算法封装起来，并让它们可以相互替换，使得算法的变化不会影响使用算法的代码，让项目更好维护和拓展。

#### 模板方法模式（待补图）

模板方法模式在抽象父类中定义了操作的标准流程，将一些具体实现步骤交给子类，使得子类可以在不改变流程的情况下对某个步骤进行定制。

#### 执行器模式（待补图）

正常情况下，可以通过工厂模式来创建不同的策略或模板方法，但由于每种生成模式的参数和返回值不同（HtmlCodeResult和MutilFileCodeResult），很难对通过工厂模式创建出来的对象进行统一的调用。

```java
public HtmlCodeResult parseCode(String codeContent) {}

public MultiFileCodeResult parseCode(String codeContent) {}

void saveFiles(HtmlCodeResult result, String baseDirPath) {}

void saveFiles(MultiFileCodeResult result, String baseDirPath) {}

```

对于方法参数不同的策略模式和模板方法模式，建议使用执行器模式（Executor）

执行器模式提供统一的执行入口来协调不同策略和模板的调用，特别适合处理参数类型不同但业务逻辑相似的场景，避免了工厂模式在处理不同参数类型时的局限性。



#### 混合模式（待补图）

最终，预期的代码架构是一种混合模式：

- 执行器模式： 提供统一的执行入口，根据生成类型执行不同的操作
- 策略模式：每种模式对应的解析方法单独作为一个类来维护
- 模板方法模式：抽象模板类定义了通用的文件保存流程，子类可以有自己的实现（比如多文件生成模式需要保存3个文件，而原生HTML模式只要保存1个文件）





## 三、应用模块

### 1、需求分析

之前实现的是单机版本，用户只能在本地生成代码文件，现在我们要将其升级为平台化系统，这意味需要支持多用户、应用管理、在线部署等功能。

需要的具体功能包括：

- 用户基础功能
- 创建应用
- 编辑应用信息
- 删除自己的应用
- 查看应用详细
- 分页查询自己的应用列表
- 分页查看精选应用列表
- 用户高级功能
- 实时查看应用效果（⭐）
- 应用部署（⭐）
- 管理功能
- 管理所有应用（删改查）
- 设置精选应用



### 2、方案设计

平台化改造的核心在于**建立完整的应用生命周期管理体系**。

#### 工作流程

用户在主页输入提示词后，系统会创建一个应用记录，然后跳转到对话页面与AI交互生成网站。生成完成后，用户可以预览效果，满意后进行部署，让网站真正对外提供服务。

这个流程看似简单，但涉及到数据存储、权限控制、文件管理、网站部署等多个技术环节。



#### 库表设计

应用表是整个项目的核心，需要记录应用的基本信息、生成配置、部署信息等。其中最关键的是deployKey字段，由于每个网站应用文件的部署都是隔离的（想象成沙箱），需要用唯一字段来区分，可以作为应用的存储和访问路径，而且为了便于访问，每个应用的访问路径不能太长。

这里我们参考美团NoCode 等平台的设计，将deployKey设置为6位英文数字组成的唯一标识符。



```sql
-- 应用表
create table app
(
    id           bigint auto_increment comment 'id' primary key,
    appName      varchar(256)                       null comment '应用名称',
    cover        varchar(512)                       null comment '应用封面',
    initPrompt   text                               null comment '应用初始化的 prompt',
    codeGenType  varchar(64)                        null comment '代码生成类型（枚举）',
    deployKey    varchar(64)                        null comment '部署标识',
    deployedTime datetime                           null comment '部署时间',
    priority     int      default 0                 not null comment '优先级',
    userId       bigint                             not null comment '创建用户id',
    editTime     datetime default CURRENT_TIMESTAMP not null comment '编辑时间',
    createTime   datetime default CURRENT_TIMESTAMP not null comment '创建时间',
    updateTime   datetime default CURRENT_TIMESTAMP not null on update CURRENT_TIMESTAMP comment '更新时间',
    isDelete     tinyint  default 0                 not null comment '是否删除',
    UNIQUE KEY uk_deployKey (deployKey), -- 确保部署标识唯一
    INDEX idx_appName (appName),         -- 提升基于应用名称的查询性能
    INDEX idx_userId (userId)            -- 提升基于用户 ID 的查询性能
) comment '应用' collate = utf8mb4_unicode_ci;

```

说明：

1. `priority` 优先级字段：我们约定99表示精选应用，这样可以在主页展示高质量的应用，避免用户看到大量测试内容。为什么用数字而不是用枚举呢？因为这样更利于扩展，比如约定999表示置顶，还可以根据数字灵活调整各个应用的具体展示顺序。
2. 添加索引：给deployKey、appName、userId三个经常用于作为查询条件的字段增加索引，提高查询性能。

注意，暂时不考虑将应用代码直接保存到数据库字段中，而是保存在文件系统里，这样可以**避免数据库和文件存储不一致**的问题，也便于后续扩展到对象存储等方案。



### 应用生成

#### 业务流程：

1. 用户在主页输入提示词创建应用（入库）
2. 获得应用id后跳转到对话页面
3. 系统自动使用初始提示词与AI对话生成网站代码

由于应用的生成过程和AI对话是绑定的，我们可以提供一个名为`chatToGenCode`的应用生成接口，调用之前开发的AI代码生成门面完成任务，并且流式返回给前端。

一定要确保生成的文件能够与应用正确关联，因此这次生成的网站目录名称不再是之前的codeType_雪花算法，而是codeGenType_appId，这样就能通过appId查数据库获取应用信息，再根据应用信息找到对应的网站目录了。

为什﻿么这里不用 dep﻿loyKey 作为‎网站目录名称呢？是希望能够区分部署环境和过程。



#### SSE流式接口优化

##### 解决空格丢失问题

前端使用EventSource对接目前的接口时，会出现空格丢生问题，解决方法是在后端封装数据，参考DeepSeek的做法，将原本的返回值封装到JSON中。甚至美团NoCode对内容进行了加密。

按照封装的思路，我们可以编写下列代码，将 Flux 额外封装成 ServerSentEvent，把原始数据放到 JSON 的 `d` 字段内：



##### 主动告诉前端生成完毕

在 SSE 中，当服务器关闭连接时，会触发客户端的 `onclose` 事件，这是前端判断流结束的标准方式。但是，`onclose`事件会在连接正常结束（服务器主动关闭）和异常中断（如网络问题）时都触发，前端就很难区分到底后端是正常响应了所有数据、还是异常中断了。

因此，我们最好在后端添加一个明确的 `done` 事件，这样可以更清晰地区分流的正常结束和异常中断。

#### 应用部署

1. 部署方案：使用Serve工具： 最简单的方案，使用serve工具快速启动一个Web服务器，为指定目录提供Web访问服务。缺点是依赖Node.js环境，需要独立启动Web服务进程，而且性能相对较低。
2. 通过SpringBoot接口：我们可以直﻿接在后端项目中实现﻿一个静态资源服务接‎口，输入部署路径，⁠返回相应的文件，优点是无需额外进程，缺点是功能相对简单，性能也不如专业的Web服务器。
3. 使用Nginx映射：Nginx是专业的Web服务器，性能优异，功能丰富，是最推荐的生产环境方案。优点是性能较好，适合生产环境，缺点是需要额外引入Nginx组件。
4. COS：用COS对象存储的静态网站访问能力，同时实现存储+范围，缺点是需要自定义域名

最终方案：

最终选择混合方案：使用Spring Boot接口实现AI生成的网页浏览，使用Nginx提供网站部署服务。

##### 接口：

部署接口接收appId作为请求参数，返回可访问的URL地址`${部署域名}/{deployKey}`

##### 部署流程：

1. 参数校验：比如是否存在App、用户是否有权限部署该应用（仅本人可以部署）
2. 生成deployKey：之前设计库表已经提到了deployKey的生成逻辑（6位大小写字母+数字），还要注意不能跟已有的Key重复，此外，每个app只生成一次deployKey，已有则不生成。
3. 部署操作：本质是将`code_output`目录下的临时文件复制到`code_deploy`目录下，为了简化访问地址，直接将deployKey作为文件名。



## 四、对话历史模块

为AI零代码应用生成平台添加对话历史管理功能， 让用户能够查看和管理历史对话记录。

### 1、需求分析

前面我们已经实现了AI生成应用的核心功能，但是每个对话都是独立的，无法让用户在原有的基础上进行版本迭代及优化。因此，我们需要实现以下需求：

1. **对话历史的持久化存储**：用户发送消息时，需要保存用户消息；AI成功回复后需要保存AI消息。即使AI回复失败，也要记录错误信息，确保对话的完整性。
2. **应用级别的数据隔离**：每个应用的对话历史都是独立的。删除应用时，需要关联删除该应用的所有对话历史，避免数据冗余。
3. **对话历史查询**： 支持分页查看某个应用的对话历史，需要区分用户和AI消息。类似聊天软件的消息加载机制，每次加载最新10条消息，支持向前加载更多历史记录（仅应用创建者和管理员可见）
   详细来说，进入应用页面﻿时，前端根据应用 id 先加载一次对话历史﻿消息，关联查询最新 10 条消息。如果存在‎历史对话，直接展示；如果没有历史记录，才自⁠动发送初始化提示词。这样就解决了之前浏览别‍人的应用时意外触发对话的问题。
4. **管理对话历史**：管理员可以查看所有应用的对话历史，按时间降序排序，便于内容监管。



### 2、方案设计

#### 分页查询

##### 传统分页查询问题

对于对话历史（聊天记录）的分页查询，不建议使用传统分页查询。Why？在传统分页中，数据通常是基于页码或偏移量进行加载的。如果数据在分页过程中发生了变化，比如插入或删除数据，用户看到的分页数据可能会不一致，导致用户错过或重复某些数据。 并且传统的offset 分页方式在处理大量的对话数据时存在严重的性能问题。假如一个热门应用积累了十万条对话记录后，如果用户想查看较早的历史记录，执行`Liimit 100000,10`就会出现**深度分页**问题，查询会非常缓慢。因为数据库需要先扫面和跳过前面100000条数据才能返回用户真正需要的10条数据。随着offset值的增大，查询性能会线性下降，在高并发场景下很容易成为系统瓶颈。

##### 游标查询

为了解决这些问题，可以使用游标分页。使用一个游标来跟着分页位置，而不是基于页码，**每次请求从上一次的游标开始加载数据**。一般会选择数据记录的唯一标识符（主键）、时间戳或者具有排序能力的字段作为游标。

建议优先使用id作为游标 ，因为主键性能最优且不重复。但是针对我们的场景，按时间排序是核心需求，而且同一个appId下时间重复的可能性极低，所以直接使用对话历史的创建时间createTime作为游标是完全可行的。不需要额外带上对话历史的id作为复合游标，简化了游标查询的逻辑。如：

```sql
SELECT * FROM chat_history 
WHERE appId = 123 AND createTime < '2025-07-29 10:30:00'
ORDER BY createTime DESC 
LIMIT 10;
```

而且还可以给appId和createTime增加复合索引，进一步提高检索效率。这样执行过程就变成了：

1. 直接定位到 (appId=123, createTime<'2025-07-29 10:30:00') 的索引位置
2. 顺序读取 10 条记录
3. 完成查询



### 库表设计

#### 1、核心设计

```sql
-- 对话历史表
create table chat_history
(
    id          bigint auto_increment comment 'id' primary key,
    message     text                               not null comment '消息',
    messageType varchar(32)                        not null comment 'user/ai',
    appId       bigint                             not null comment '应用id',
    userId      bigint                             not null comment '创建用户id',
    createTime  datetime default CURRENT_TIMESTAMP not null comment '创建时间',
    updateTime  datetime default CURRENT_TIMESTAMP not null on update CURRENT_TIMESTAMP comment '更新时间',
    isDelete    tinyint  default 0                 not null comment '是否删除',
    INDEX idx_appId (appId),                       -- 提升基于应用的查询性能
    INDEX idx_createTime (createTime),             -- 提升基于时间的查询性能
    INDEX idx_appId_createTime (appId, createTime) -- 游标查询核心索引
) comment '对话历史' collate = utf8mb4_unicode_ci;

```

#### 2、扩展设计

1. 可以按需添加 `parentId` 字段，将 AI 消息和对应的用户提示词进行关联，便于生成失败时的重试、或者用户手动重新生成。 

   ```sql
   parentId   bigint  null comment '父消息id（用于上下文关联）',
   ```

   ​				

2. 如果需要保存每个版本的代码文件，还可以添加 `fileList` 字段，结构为 JSON 数组格式，这样每条消息就对应一个代码版本。不过代码文件很大时，存到数据库里不是一个合适的选择。



### 对话记忆

#### 1、需求分析

很多时候AI生成的网站无法一次性满足用户的需求，因此需要提供网站修改功能。但是目前我们的AI对话会断片，无法记住之前的对话内容，每次修改实际上都是重新生成完整的网站，而不是在原有基础上进行修改。这种情况下，用户不能进行迭代式的网站开发，每次都是开盲盒，极大限制了平台的适应性。

#### 2、方案设计

要解决这个问题，就要给AI增加对话记忆能力。

##### **那对话记忆要保存到哪里呢**？

LangChain4j不仅提供了对话记忆能力，而且还能结合Redis持久化对话记忆。

**那为什么不用内存或者MySQL来存储会话记忆呢？**

不用内存是因为重启后会丢失记忆，而且如果每个应用都在内存中维护对话历史，很容易出现OOM问题。

不用MySQL一方面是因为Redis作为内存数据库，在读写对话记忆时性能更高；另一方面是数据库中的对话历史表包含其他业务字段，不适合直接交给LangChain4j的对话记忆组件管理。

##### 加载历史

要注意的是，Redis的内存也不是无限的，一般情况下要给存入Redis的每个Key都设置合理的过期时间，不能不过期，所以这就可能导致Redis的会话记忆被删除的情况。那又该如何解决呢？方案很简单，之前我们已经在数据库中保存了用户和AI的消息，只需要在初始化会话记忆时，加载最新的对话记录到Redis中，就能确保AI了解交互历史。

**大致流程**： AI对话 =》从数据库中加载对话历史到Redis =》Redis为AI提供会话记忆



##### 对话隔离

此外，每个应用的对话记忆应该是相互隔离的，LangChain4j也提供了对话记忆隔离的能力。



##### 使用对话记忆

**方案1-- 内置隔离机制**

**方案2--AI Service 隔离**



#### 扩展思路

1. **记录应用对话总轮数**：统计每个应用的对话轮数，这个数据可以用于分析用户使用习惯，也可以作为应用复杂度的参考指标。
2. **对话历史导出功能**：支持到处对话记录为Markdown文件，方便用户保存和分享开发过程。
3. **智能记忆管理（较难）**：利用AI分析对话次数较多的应用，智能总结过去的对话历史，节省Token的同时优化记忆效果。
4. **多人协作对话（较难）**：允许多个用户共同参与一个应用的对话，实现团队协作开发。





## 五、工程项目生成

目前平台只支持生成原生网站，在实际使用中有一定局限性。我们将让其生成更复杂的前端工程化项目，提高本平台的实用性。

### 1、需求分析

前端工程化项目是指使用现代化工具链、规范化流程和组件化架构来构建的前端应用。相比传统的 HTML、CSS、JavaScript 三件套，它具备模块管理、自动化构建、代码分割、热更新等现代开发特性，能够更轻松地开发复杂网站。
现在很多前端工程化项目都是使用 Vue 或 React 框架，结合 Vite等打包构建工具，再加上 ESLint 之类的代码规范校验库来实现的。

调研其他平台，美团NoCode平台支持React工程项目，我们不妨以Vue作为示例，让平台能够生成完整的Vue3 +Vite 工程项目，并跟其他两种生成模式一样，实现流式输出、网站浏览和部署。

考虑到成本问题，大模型的能力受限，有时效果并不是很理想，但不妨碍我们进行尝试。



### 2、方案设计

#### 方案选型分析

**方案1 - 直接输出Markdown**

这种方案延续之前的思路，直接让AI在输出的Markdown中包含代码块，然后通过解析的方式保存文件

```markdown
这是我生成的项目：
```vue
App.vue ```


``` json
package.json  ```

```

优点是实现简单，好理解，实时展示效果好，缺点是如果代码量较大，一次对话可能无法完整输出，容易出现代码不全或者解析错误的情况。

**方案2 - 工具调用**

给AI提供保存文件等工具，让AI来决定什么时候保存文件、保存哪些文件、要保存什么代码到文件中。这种方式的基本实现很简单，不需要自己解析AI的输出并保存文件，全都交给AI和框架来处理。但想要实时展示工具调用信息就很复杂了，需要解析AI响应的工具调用，但是由于流式输出的特性，AI是一点一点的把信息吐出来，这样拼接起来就很有难度。

**方案3 - Agent模式**

智能体(Agent)是指能够感知环境、进行推理、制定计划、做出决策并自主采取行动以实现特定目标的 AI系统。它以大语言模型为核心，集成 **记忆、知识库和工具** 等能力为一体，构造了完整的决策能力、执行能力和记忆能力，就像一个有主观能动性的人类一样。
简单来说，Agent 的特点是 **先规划再执行**。比如先制定网站生成计划、然后分别在每个步骤中生成一个文件并解析。

```markdown
步骤 1：我要生成网站文件 page1.vue、page2.vue、page3.vue
步骤 2：生成 page1.vue，然后保存
步骤 3：生成 page2.vue，然后保存
步骤 4：生成 page3.vue，然后保存
步骤 5：生成网站成功，退出执行
```

优点是每一个步骤非常清晰，在步骤内我可以通过工具调用来实现文件保存，也可以单独调用AI获取到生成的代码，然后通过程序保存，这样实现流式输出就很简单了。此外，由于划分了多个步骤，即使某一个步骤出错，也能中断恢复，从而能够处理长逻辑的复杂任务。

但是缺点也是很明显的，那就是需要多次调用AI，输出结构更加不可控，成本也会更高，并且Agent模式的整体结构更复杂，需要自己设计Agent流程。

#### 最终方案

由于LangChain4j 本身就支持AI多次调用工具，相当于已经实现了基础的Agent多步骤执行能力，因此考虑到开发复杂度，我们最终选择**方案2 - 工具调用**



#### 系统提示词

我们需要定义新的生成模式Vue工程模式(vue_project)，这种模式使用DeepSeek 的推理模型，提供的系统提示词也会更复杂。

```markdown
你是一位资深的 Vue3 前端架构师，精通现代前端工程化开发、组合式 API、组件化设计和企业级应用架构。

你的任务是根据用户提供的项目描述，创建一个完整的、可运行的 Vue3 工程项目

## 核心技术栈

- Vue 3.x（组合式 API）
- Vite
- Vue Router 4.x
- Node.js 18+ 兼容

## 项目结构

项目根目录/
├── index.html                 # 入口 HTML 文件
├── package.json              # 项目依赖和脚本
├── vite.config.js           # Vite 配置文件
├── src/
│   ├── main.js             # 应用入口文件
│   ├── App.vue             # 根组件
│   ├── router/
│   │   └── index.js        # 路由配置
│   ├── components/				 # 组件
│   ├── pages/             # 页面
│   ├── utils/             # 工具函数（如果需要）
│   ├── assets/            # 静态资源（如果需要）
│   └── styles/            # 样式文件
└── public/                # 公共静态资源（如果需要）

## 开发约束

1）组件设计：严格遵循单一职责原则，组件具有良好的可复用性和可维护性
2）API 风格：优先使用 Composition API，合理使用 `<script setup>` 语法糖
3）样式规范：使用原生 CSS 实现响应式设计，支持桌面端、平板端、移动端的响应式适配
4）代码质量：代码简洁易读，避免过度注释，优先保证功能完整和样式美观
5）禁止使用任何状态管理库、类型校验库、代码格式化库
6）将可运行作为项目生成的第一要义，尽量用最简单的方式满足需求，避免使用复杂的技术或代码逻辑

## 参考配置

1）vite.config.js 必须配置 base 路径以支持子路径部署、需要支持通过 @ 引入文件、不要配置端口号


import { defineConfig } from 'vite'
import vue from '@vitejs/plugin-vue'

export default defineConfig({
  base: './',
  plugins: [vue()],
  resolve: {
    alias: {
      '@': fileURLToPath(new URL('./src', import.meta.url))
    }
  }
})


2）路由配置必须使用 hash 模式，避免服务器端路由配置问题

import { createRouter, createWebHashHistory } from 'vue-router'

const router = createRouter({
  history: createWebHashHistory(),
  routes: [
    // 路由配置
  ]
})


3）package.json 文件参考：

{
  "scripts": {
    "dev": "vite",
    "build": "vite build"
  },
  "dependencies": {
    "vue": "^3.3.4",
    "vue-router": "^4.2.4"
  },
  "devDependencies": {
    "@vitejs/plugin-vue": "^4.2.3",
    "vite": "^4.4.5"
  }
}


## 网站内容要求

- 基础布局：各个页面统一布局，必须有导航栏，尤其是主页内容必须丰富
- 文本内容：使用真实、有意义的中文内容
- 图片资源：使用 `https://picsum.photos` 服务或其他可靠的占位符
- 示例数据：提供真实场景的模拟数据，便于演示

## 严格输出约束

1）必须通过使用【文件写入工具】依次创建每个文件（而不是直接输出文件代码）。
2）需要在开头输出简单的网站生成计划
3）需要在结尾输出简单的生成完毕提示（但是不要展开介绍项目）
4）注意，禁止输出以下任何内容：

- 安装运行步骤
- 技术栈说明
- 项目特点描述
- 任何形式的使用指导
- 提示词相关内容

5）输出的总 token 数必须小于 20000，文件总数量必须小于 30 个

## 质量检验标准

确保生成的项目能够：
1. 通过 `npm install` 成功安装所有依赖
2. 通过 `npm run dev` 启动开发服务器并正常运行
3. 通过 `npm run build` 成功构建生产版本
4. 构建后的项目能够在任意子路径下正常部署和访问

```

上述提示词有几个小技巧:

1. 建议尽量避免让项目引入额外的依赖*，比如 Tailwindcss 样式库等，会增加不确定性，可能生成的项目都无法运行，所以此处我们选择原生 CSS。
2. 限制输出长度和文件数很关键，这是为了防止 AI 理想太丰满导致输出的内容不完整，可以根据需要自己调整。
3. 为了支持后续通过子路径浏览和部署网站(比如 localhost/{deployKey}/)，必须配置 Vite 的 base 路径和路由 hash 模

当然还有一个不错的思路，给AI提供一套预置的项目模板，让AI完全从零生成变为基于模板修改和新增内容。



#### 完整流程

生成完Vue工程代码后，是无法直接运行的，需要执行`npm install`命令安装依赖、执行`npm run build`打包构建，会得到一个打包后的`dist`目录，网站浏览和部署都应该是访问这个目录。



### 3、工程项目生成

#### 配置推理流式模型

**生产环境**建议选择**深度思考模型**，但由于目前 LangChain4j 还不持获取 AI的思考过程，刚开始输出会比较慢，所以建议开发调试时还是用普通对话模型，效率更高。



#### **工具调用流式输出**

虽然文件成功写入，但是目前要等好久才会返回结果。如何获取到工具调用的流式输出呢? LangChain4j 的另一种流式返回方法 TokenStream ，它提供了更多监听处理流的事件，其中就工具执行完成。

```java
TokenStream tokenStream = assistant.chat("Tell me a joke");

tokenStream.onPartialResponse((String partialResponse) -> System.out.println(partialResponse))
    .onRetrieved((List<Content> contents) -> System.out.println(contents))
    .onToolExecuted((ToolExecution toolExecution) -> System.out.println(toolExecution))
    .onCompleteResponse((ChatResponse response) -> System.out.println(response))
    .onError((Throwable error) -> error.printStackTrace())
    .start();
```

但是LangChain对工具调用流式输出的支持度并不好，没有相应的回调，GitHub上就有人提出并提供出了解决方案。

我的做法是，复制 lssues 的相关源码到项目的 dev.langchain4j包(跟 LangChain4j里的包相同路径)，如果 `src/main/java`中有与依赖jar 包中相同包名和类名的类，本地类会优先被加载，依赖jar 中的类会被完全忽略。这样就实现了对源码的覆盖和增强，给TokenStream增加了两个回调函数。



#### **统一消息格式**

之前我们只需要给前端返回 A的响应信息，但现在还需要返回工具调用信息(后续还有可能需要返回深度思考信息)，因此需要约定一种消息格式，来区分不同的信息类型。包括：

- AIx响应消息
- 工具调用消息
- 工具调用完成消息



#### TokenStream流处理过程

调用AI对话方法时，我们可以获得TokenStream流，接下来要这么对TokenStream进行处理呢？这就要从需求出发了，考虑后端对话记忆要保存什么内容？前端需要看到什么内容？

1. 假设AI原始返回的内容是：

   ```json
   AI 响应 {"为你生成代码"}
   
   工具调用请求 {index=0, id="call_0", name="writeFile", arguments="流式参数"}
   工具调用请求 {index=0, id="call_0", name="writeFile", arguments="流式参数"}
   工具调用请求 {index=0, id="call_0", name="writeFile", arguments="流式参数"}
   工具调用完成 {index=0, id="call_0", name="writeFile", arguments="完整参数"}
   
   工具调用请求 {index=1, id="call_1", name="writeFile", arguments="流式参数"}
   工具调用请求 {index=1, id="call_1", name="writeFile", arguments="流式参数"}
   工具调用请求 {index=1, id="call_1", name="writeFile", arguments="流式参数"}
   工具调用完成 {index=1, id="call_1", name="writeFile", arguments="完整参数"}
   
   AI 响应 {"生成代码结束"}
   
   ```

2. 接下来，我们要统一封装消息，便于下游处理

   ```java
   {type="ai_response", data="为你生成代码"}
   
   {type="tool_request", index=0, id="call_0", name="writeFile", arguments="流式参数"}
   {type="tool_request", index=0, id="call_0", name="writeFile", arguments="流式参数"}
   {type="tool_request", index=0, id="call_0", name="writeFile", arguments="流式参数"}
   {type="tool_executed", index=0, id="call_0", name="writeFile", arguments="完整参数"}
   
   {type="tool_request", index=1, id="call_1", name="writeFile", arguments="流式参数"}
   {type="tool_request", index=1, id="call_1", name="writeFile", arguments="流式参数"}
   {type="tool_request", index=1, id="call_1", name="writeFile", arguments="流式参数"}
   {type="tool_executed", index=1, id="call_1", name="writeFile", arguments="完整参数"}
   
   {type="ai_response", data="生成代码结束"}
   
   ```

3. 拿到这些信息后，后端需要对流进行处理，一方面是按需返回给前端，另一方面是保存对话记忆到数据库中。保存到数据库中的对话记忆格式为：

   ```markdown
   为你生成代码：
   
   [工具调用] 写入文件 src/index.html
   ```html
   写入的代码
   
   
   [工具调用] 写入文件 src/about.html
   ```html
   写入的代码
   
   
   生成代码结束！
   
   ```

   上述内容可以直接通过ToolExecutedMessage工具调用完成消息获取到。

4. 返回给前端的内容也是类似的，只不过是为了减少用户等待，首次调用某一个工具时就应该告诉用户“选择工具”信息。其他内容跟要保存的对话记忆是一致的，这样设计不仅减少了定制开发的成本，用户刷新后看到的内容和实时生成时看到的内容也是一致的。

   ```markdown
   为你生成代码：
   
   [选择工具] 写入文件
   [工具调用] 写入文件 src/index.html
   ```html
   写入的代码 ```
   
   
   [选择工具] 写入文件
   [工具调用] 写入文件 src/about.html
   ```html
   写入的代码 ```
   
   
   生成代码结束！
   
   ```

   整个AI流式处理过程图：

   



Flux 流处理器

接下来，我们还要编写下游的Flux流处理器，之前我们是在AppService的chatToGenCode生成方法内处理了原生模式生成的流。现在由于Vue生成模式的消息被封装成了JSON格式消息，所以我们最好针对每类生成模式单独定义一个流处理器，防止逻辑相互影响。

- 原生文本流处理器（原生模式使用）
- JSON消息流处理器(Vue工程使用)

然后再定义一个执行器，根据生成类型调用不同的流处理器。

JSON消息流处理器，在原生流处理器的基础上增加了2个逻辑：

1. 消息解析：需要根据消息类型，将JSON字符串转换为对应的消息对象，然后提取属性进行其他操作(比如返回给前端、或者拼接起来保存到数据库中)
2. 输出选择工具消息：虽然我们后端实现了工具调用的流式输出，但是考虑到前端不好对这些消息进行解析和处理，因此我们只在**同一个工具第一次输出时**，输出给前端“选择工具”的消息。可以利用一个集合来判断某个id的工具是否为首次输出。



### 4、扩展思路

1. 为AI提供代码模板
2. 深度思考 ： LangChain4j 的 v1.2 版本已经支持深度思考的流式输出特性，直接监听TokenStream的onPartialThinking 事件就能实现了



## 六、拓展功能

前面我们已经了AI零代码应用生成平台的核心功能，可以通过简单的对话生成各种类型的前端应用。

这次我们将继续为平台扩展更多功能：

- 生成应用封面图
- 下载项目代码包
- AI 智能选择方案



### 生成应用封面图

#### 1、需求分析

如果每个应用都有一个精美的预览图，会让整个平台看起来跟家专业和吸引人。参考其他的大厂平台，可以直接将网站实际的运行效果作为应用封面图，而且要自动生成。

#### 2、方案设计

##### 实现流程

1. 首先要获取到应用的可访问URL。由于我们的平台支持多种生成模式（HTML、多文件项目、Vue工程），其中原生模式和Vue 工程模式生成可访问浏览 URL的时机不一样。所以为了统一处理，而且确保应用已经可以正常访问，我们选择在 **应用部署完成后再生成封面图**。
2. 使用 `Selenium`这样的自动化工具打开一个无头浏览器，访问应用页面并进行截图。
3. 直接截图得到的图片通常比较大，不仅占用存储空间，加载速度也比较慢。因此我们需要对图片进行压缩处理。 虽然我们可以通过调整 Selenium 的窗口大小来控制截图尺寸，但这样可能会导致页面显示不全。更好的方案是 先按正常尺寸截图，然后使用工具库对图片进行压缩。
4. 为了确保图片的持久化存储和快速访问，将压缩后的图片上传到腾讯云COS对象存储种，并将访问URL保存到数据库的应用表中。
5. 最后，记得清理本地临时文件。

##### 网页截图技术方案选型

![image-20250819235023359](D:\code\wang-ai-code-generator\ReadMe.assets\image-20250819235023359.png)

追求稳定性选Selenium，追求性能选Playwright，如果用Node.js技术栈就选Puppeteer，有充足预算就选云服务API，考虑到我们是Java技术栈，以及对稳定性的要求，最终选择 Selenium。

##### 什么是Selenium

Selenium 是一个非常成熟的Web自动化框架，它的核心概念是WebDriver（浏览器驱动）。WebDriver 是一个可以控制浏览器行为的接口，能够让程序像人类一样操作浏览器：打开页面，点击按钮、输入文本、截取屏幕等。可以说WebDriver是Selenium 与浏览器之间的桥梁，因为不同浏览器 有不同的内部API 和控制机制，驱动程序负责将Selenium的标准化命令翻译成各个浏览器能理解的具体指令，从而实现跨浏览器的统一自动化控制。

在实际使用Selenium 时，最好搭配 **WebDriverManager** 使用。 WebDriverManager 是一个自动管理浏览器驱动程序的工具库，它解决了很多实际开发中的痛点：

1. 自动下载驱动程序： 根据系统上安装的浏览器版本，自动下载对应的驱动程序。
2. 版本匹配： 确保驱动程序版本与浏览器版本兼容
3. 路径管理：自动设置系统属性，告诉 Selenium 驱动程序的位置
4. 缓存机制： 下载的驱动程序会被缓存，避免重复下载。

![image-20250820090507636](D:\code\wang-ai-code-generator\ReadMe.assets\image-20250820090507636.png)

##### 开发：

1. 本地截图生成
2. 保存截图到对象存储
3. 截图服务
4. 触发截图生成

#### 3、扩展思路：

##### 截图服务优化：

目前在生成截图时，我们是通过静态方法初始化了一个全局共用的WebDriver，来避免重复加载。单纯是为了追求性能。但是在并发截图的场景下，如果复用同一个 WebDriver，可能会导致截图了错误的页面。

```java
// 危险：多线程共享同一个driver
private static final WebDriver webDriver = new ChromeDriver();

// 线程A: driver.get("page1.html") -> 截图
// 线程B: driver.get("page2.html") -> 截图  
// 结果：线程 A 可能截到 page2 的内容
```

可以这样优化：

1. 每次创建新实例

   ```java
   public static String saveWebPageScreenshot(String webUrl) {
       WebDriver driver = initChromeDriver(); // 每次新建
       try {
           driver.get(webUrl);
           return takeScreenshot(driver);
       } finally {
           driver.quit(); // 用完就关闭
       }
   }
   ```

   优点：好理解，缺点是重复初始化驱动会严重影响性能，不推荐。

2. 连接池模式。维护一个WebDriver 池，按需分配和回收。

   ```java
   @Component
   public class WebDriverPool {
       private final Queue<WebDriver> pool = new ConcurrentLinkedQueue<>();
       
       public WebDriver borrowDriver() { /* 获取空闲driver */ }
       public void returnDriver(WebDriver driver) { /* 归还driver */ }
   }
   ```

   优点：更灵活地复用线程。缺点：实现成本较大，而且需要额外维护池。

3. ThreadLocal 模式。每个线程使用同一个 WebDriver

   ```java
   private static final ThreadLocal<WebDriver> driverThreadLocal = new ThreadLocal<>();
   
   public static WebDriver getDriver() {
       WebDriver driver = driverThreadLocal.get();
       if (driver == null) {
           driver = initChromeDriver();
           driverThreadLocal.set(driver);
       }
       return driver;
   }
   
   ```

   比较推荐这种方案，实现复杂度一般，而且能够解决并发问题。缺点是如果你的线程数较多，WebDriver也较多，一致不释放，可能会导致 内存溢出。

4. 使用队列。将要执行的截图任务依次放到队列中，WebDriver 线程组依次取出任务执行，本质是并行变串行。 一种比较简单的实现：
    用newSingleThreadExecutor()确保只有一个处理线程，让所有截图任务串行。
   用CompletableFuture 提交任务，自动处理任务队列和异步返回。

   ```java
   @Component
   public class ScreenshotManager {
       private static final WebDriver webDriver = initChromeDriver();
       private final ExecutorService executor = Executors.newSingleThreadExecutor();
       
       public CompletableFuture<String> takeScreenshot(String url) {
           return CompletableFuture.supplyAsync(() -> {
               webDriver.get(url);
               return doScreenshot(webDriver);
           }, executor);
       }
   }
   
   ```

   优点：性能好，可以异步返回结果、不阻塞调用方。缺点是实现复杂度较大。不过如果并发量和稳定性要求很高，可以考虑用消息队列(如RabbitMQ 或 Kafka)

### 下载项目代码包

#### 1、需求分析

除了在线预览和使用生成的应用，用户可能需要下载代码到本地进行二次开发。这样一来，我们平台不仅是一个在线工具，更是一个真正的开发起点。

#### 2、方案设计

实现代码下载功能需要考虑几个关键步骤：

1. 基础校验：我们需要验证应用是否存在、用户是否有下载权限等。考虑到安全性，只有应用的创建者才能下载对应的代码。
2. 找到应用的生成目录。这里要特别注意，我们要下载的是 **原始的生成目录**，而不是部署目录。部署目录是打包构建之后的文件，而生成目录包含的是源代码。
3. 定义文件过滤器，因为并不是所有文件都需要提供给用户下载。比如 `node_modules` 目录体积庞大且可以通过 `npm install` 重新安装，`dist` 和 `build` 目录是构建产物可以重新生成，`.DS_Store`、`.env` 等文件包含系统信息或敏感配置不应该下载。
4. 最后将过滤后的文件打包成 ZIP 压缩包，通过 HTTP 响应直接返回给前端。需要设置正确的响应头，告诉浏览器这是一个需要下载的文件、并且传递下载的文件名称

#### 3、扩展思路：

1. 判断应﻿用是否已经生成了浏﻿览地址，只有生成了‎地址的应用才允许下⁠载（需要后端配合修‍改逻辑）。
2. 添加下﻿载统计功能，记录每个﻿应用的下载次数，有助‎于了解用户行为和优化⁠系统，比如利用 CD‍N 对热门应用进行加速。

### AI 智能选择方案

#### 1、需求分析

目前有3套不同的代码生成方案：原生HTML，原生多文件、Vue工程。那么问题来了，用户提出需求时，如何判断应该使用哪一个方案呢？让用户选择的话，会增加用户的使用门槛。更好的方案是让AI来自动判断，这就是所谓的智能路由。

#### 2、方案设计

在实际生产环境中，智能路由本身应该选择 成本更低、输出更快的大模型。



## 七、可视化修改





## 八、AI工作流

引入一个全新的技术架构——AI智能体工作流，通过LangGraph4j 框架重构代码生成逻辑，并补充搜集图片素材、代码质量检查等过程，让生成的网站更真是可靠。

### 1、需求分析

目前生成的网站内的图片都是随机占位图片，实际上可以根据网站类型补充素材图片，让生成的网站更真实。如果想要快速实现这个需求，其实只需要提供给 AI 图片搜索工具就好，交给框架和 AI 来决定什么时候调用工具，自动执行。但是，对于可标准化的工作流程（搜集图片是在生成网站前的固定步骤），**能标准化的建议标准化，**不要交给 AI 自主判断，这样可以减少随机性和误差，而且还可以自主对路程进行新增、编排和优化。

因此，接下来我们将使用一套全新的网站生成方案——基于工作流来实现。

原本我们是把各个流程自己分散到了Sevice等类的各个方法，比如获取代码生成类型、调用AI流式输出、保存文件、打包构建等。而现在，我们需要把这一套流程用工作流组合起来。

### 2、工作流方案选型

为了实现 AI 工作流，我们可以考虑市面上很多现成的平台，像Dify、Coze、阿里云百炼，通过拖拽式的界面就能快速搭建工作流，上手简单、能够快速看到效果，非常适合快速验证想法或者让非技术人员参与构建流程。

但是，当涉及到复杂的业务逻辑时，“低代码平台” 可能无法满足我们的定制化需求，尤其是当系统需要与现有的业务逻辑深度集成时。相比之下，LangGraph4j 这样的工作流编程框架虽然需要一定的学习成本，但它提供了完全的控制能力。对于我们这个项目来说，既要与现有的 Spring Boot 系统深度集成，又要处理图片收集、AI代码生成、质量检查等复杂的业务逻辑，选择 LangGraph4j 会更加合适。

当然，更重要的是，LangGraph4j作为一个专门为 Java 生态设计的工作流框架，和 LangChain4j兼容性很好，能够无缝融入我们现有的技术栈，可以直接复用项目中已有的Service、配置和工具类，不需要从0进行开发。同时，它还提供了丰富的高级特性，比如条件边、循环执行、并发处理等，让我们能够构建出智能化的工作流程。
从长远来看，选择编程框架而不是别人的低代码工作流平台，还有一个重要优势:**可维护性和扩展性**。随着业务的发展，我们的工作流可能会变得越来越复杂，编程框架能够更好地支持这种迭代，而不会像低代码平台那样遇到天花板。



### 3、LangChain4j 入门

LangGraph4j 是一个 Java 实现的开源 AI 工作流框架，它受到了 Python 版本 LangGraph 的启发，能够与 Langchain4j 和 Spring Al 无缝集成，而且这个框架还是 **开源** 的。当然，现在的技术还不是很成熟，文档还不是很完善，但是已经能够满足大多数工作流开发的需求。

#### 核心特性

##### 1、StateGraph 工作流图

主要使用的核心类，用于定义应用程序的结构。 它将复杂的 AI 工作流抽象成 **有向图**的概念。每个**节点**代表一个具体的操作单元，比如调用 LLM生成文本、搜索外部数据、处理用户输入等。节点之间用 **边**来连接，多个节点之间通过 **状态**来共享数据，形成了一个完整的处理流程。

和传统的有向无环图（DAG）不同，LangChain4j 支持循环，比如 一个智能体可能需要根据结果回到之前步骤进行重试，或者需要某个条件满足之前持续循环执行某个逻辑。 注意，使用图之前必须编译，编译过程不仅会进行基础的结构检查（比如检查是否有孤立的节点），还会定义运行时参数，创建一个不可变的、可运行的图 `CompiledGragh<S extends AgentState>`

##### 2、AgentState 状态

 AgentState 是整个工作流的状态载体，它本质上是一个`Map`,在不同节点之间传递。每个节点都可以从这个状态中读取数据，并返回对状态的更新。

##### 3、Nodes 工作节点

节点就是图的构建块，负责执行具体的操作。一个节点通常是一个函数或一个实现了`NodeAction<S>`或`AsyncNodeAction<S>`接口的类，可以在其中编写具体的操作代码。

节点的工作流程：首先接收当前的AgentState 状态作为输入，然后执行某些计算（比如调用LLM、执行工具、运行自定义业务逻辑），最后返回一个`Map<String,Object>`，表示对状态的更新。这些更新会根据 Schema 中定义的 Reducer 应用到 AgentState中。

节点可以是同步的，也可以是异步的，甚至可以多个节点同时执行。 LangGraph4j还定义了两个特殊的节点：**START** 和 **END**。 START 节点表示图的入口点，END节点表示执行路径的结束点。

##### 4、Edges 边

边定义了节点之间的控制流，决定了工作流的执行路径。也就是说节点负责干活，边负责决定下一步。边又分为普通边、条件边、入口点

##### 5、Checkpoints 检查点

检查点运行你保存图在任何步骤的状态，也就是状态的持久化，有利于调试和恢复复杂的工作流。

**核心作用主要体现在**：

1. 支持人类检查、中断和批准工作步骤。
2. 允许通过线程隔离不同用户的交互，并且相同用户可以恢复之前的记忆。



#### 高级特性

##### 1、Streaming 异步和流式处理

##### 2、可视化

##### 3、Parallel Branch 并发

##### 4、Subgraphs 子图

##### 5、Breakpoint 断点



#### 核心工作流开发

##### 1、工作流开发步骤

工作流开发的核心： 节点+边+状态+其他特性。

具体步骤：

1. 定义工作流结构（所有工作节点先只是临时输出、也无需记录状态）
2. 定义状态
3. 定义工作节点，先通过假数据模拟状态流转
4. 开发真实的工作节点
5. 工作流中使用节点，提供完整的工作流服务

##### 2、定义工作流结构

根据我们的需求梳理出工作流程：

1. 输入原始 Prompt
2. 获取图片素材 Agent： 通过工具调用从不同的渠道获取图片
3. 内容图片： pexels 网页搜索
4. 插画图片： undraw 抓取
5. 画架构图： 文本绘图 + 上传到COS
6. Logo 等设计图片： AI 生成或者 MCP
7. 提示词增强： 关联图片内容到原始提示词
8. 智能路由 Agent： 选用哪种模式生成网站
9. 原生HTML
10. 原生多文件
11. Vue 工程
12. 网站生成 Agent： 利用搜集到的图片，根据上一步确认的生成模式来生成网站
13. 项目构建器： 文件保存/打包构建



##### 3、定义状态

![image-20250822171618209](D:\code\wang-ai-code-generator\ReadMe.assets\image-20250822171618209.png)

##### 4、定义工作节点







## 九、系统优化

目前 AI 零代码应用生成平台已经具备了完整的功能。但是还有诸多方面可以优化。我们将从以下几个方面进行系统优化：

1. 性能优化
   - AI 并发调用： 解决目前只能同时处理一个AI 请求的瓶颈问题
   - Redis 缓存：通过缓存主页精选内容提升响应速度
2. 实时性优化
   - 实时浏览： 确保用户生成网站后能立刻看到最新效果
3. 安全性优化
   - 流量保护： 为AI 对话接口实现限流限频机制
   - Prompt 审查： 防范恶意输入和注入攻击
4. 稳定性优化
   - 重试策略： 通过护轨机制提升系统容错能力
   - 工具调用优化： 解决 AI 工具调用的无线循环问题
5. 成本优化
   - AI 大模型成本控制： 根据不同场景选择合适的模型



### 1、性能优化

#### AI 并发调用问题

##### 问题分析

在实际使用过程中，我们发现了一个严重的性能瓶颈： 当多个用户同时使用平台时，只有第一个用户的 AI 请求能够正常处理，后续的请求都会被阻塞， 需要等待前面的请求完全处理完毕后才能开始执行。用户量较少时可能不太明显，但是随着平台用户的增多，这个问题会越发严重，用户等待的时候会非常长，严重影响用户的体验感。这样肯定不行！那么这个问题的根源在哪里呢？

经过分析，发现问题出现在 AI 大模型的 `ChatModel`采用了单例模式。虽然`StreamingChatModel`返回的是Flux响应式流，表面上看起来是异步的，但其底层的`SpringRestClient.execute()`方法内部实际上是同步解析数据流的，导致了**串行执行**问题。

为了验证分析，进行了测试，发现即使是不同的 AI Service 实例，只要使用的是同一个 `ChatModel`，依旧会出现阻塞现象。

##### 解决方案 -  多例模式

寻找解决方案的过程中，我发现 LangChain4j 官方提到，使用不同的对话记忆 id 就能解决并发问题。但其实这只是一个敷衍的回答，经过实际测试，我们发现使用不同的 id 虽然能区分不同用户的对话，但并没有解决并发阻塞的核心问题。

所以解决问题的关键就是： **哪儿阻塞，就针对哪儿解决**。

可以为每次 AI Service 调用使用独立生成的 ChatModel 实例。

有2种具体的方法：

- 工厂模式： 编写一个专门的工厂类，提供创建新的 `ChatModel`实例的方法。
- Spring 多例模式： 利用Spring 的Bean 作用域机制，从Spring 容器中获取新的 ChatModel 实例。

这里我们选择Spring 多例模式，它更符合Spring 的设计理念和最佳实践，而且代码实现更加剪辑呃呃呃呃呃呃，维护成本也更低。



#### Redis 缓存优化

解决了并发问题后，我们继续优化系统的响应速度。对于那些访问频率高但更新频率低的数据，使用缓存可以显著减少数据库查询次数，提升用户体验。

##### 缓存策略设计

设计缓存时一般考虑几个问题： 存什么？怎么存？存多久？怎么更新？

**一般缓存高频访问的、低频更新的数据**

比如对于我们的项目，主页精选应用就很适合缓存。具体来说就是缓存前10页的精选应用列表数据。因为绝大多数用户指挥浏览前几页的内容，很少会有人翻到后面。而且精选应用是由管理员手动设置的，更新频率相对较低。

对于这种场景，我们采用最主流的 **旁路缓存** 模式：

- 查询时先检查缓存，命中则直接返回
- 缓存未命中则查询数据库，并将结果写入缓存中
- 设置合理的过期时间，无需主动删除缓存



### 2、实时性优化

#### 当前问题

如果是Vue 工程模式生成，用户在 AI 生成完代码后无法实时浏览到网站效果，或者看到的还是旧版本的页面。这是因为我们之前采用的是异步打包策略，当用户看到 AI 回复完成时，Vue 项目可能还在后台构建中，存在时间差。

#### 解决方案

##### 方案调研

实现实时浏览的方案较多，这里通过一张表格列举：

![image-20250823152633947](D:\code\wang-ai-code-generator\ReadMe.assets\image-20250823152633947.png)

##### 最终解决方案

显然，最简单有效的解决方案是 **同步打包**。 除了简单之外，还能保证逻辑更加一致。



### 3、安全性优化

#### 流量保护

随着平台用户的增长，我们需要实现多层级的流量保护机制，防止恶意攻击和资源滥用。AI 对话接口作为最核心的也是成本最高的功能，更需要重点保护。

##### 实现方案 - Redisson 分布式限流

Redisson 实现了基于令牌桶算法的 RRateLimiter。 工作原理如下：

1. 令牌桶： 系统维护一个固定数量的令牌桶。
2. 令牌生成： 以固定速率向桶中添加令牌
3. 请求处理： 每个请求需要消耗一个令牌才能被处理
4. 限流效果： 当桶中没有令牌时，请求被拒绝或者排队。

这种算法的优势在于允许突发流量（桶中有足够多的令牌时），同时保证长期的平均速率不超过设定值。



##### 优化SSE 错误处理

在测试过程中，我们发现了一个问题： 当限流触发时，前端无法正确显示后端返回的错误信息。这是因为限流异常在进入SSE 接口之前就被抛出了，没有通过流式返回，需要特殊处理。

思路： 将限流异常消息也作为SSE 返回给前端。



#### Prompt 安全审查 - 护轨机制

防范恶意输入 和 Prompt 注入攻击。



#### 什么是护轨 Guardrails？

护轨是 AI 应用﻿中的安全机制，类似于道路上的护栏，用﻿于防止恶意的 Prompt 输入、防‎止 AI 模型产生不当或有害的内容。⁠                  ‍              

其实我们把它理解为拦截器就好了，护轨分为两种：

- 输入护轨（Input Guardrails）：在用户输入传递给 AI 模型之前进行检查和过滤
- 输出护轨（Output Guardrails）：在 AI 模型生成内容后进行检查和过滤

除了输入 ﻿Prompt 和 ﻿AI 输出结果的安‎全校验外，你还可以⁠利用护轨进行权限校‍验、日志记录等

下面我们来﻿利用输入护轨实现 ﻿Prompt 安全‎审核，防止一些非法⁠ Prompt，比‍如：

- 拒绝过长的 Prompt
- 拒绝包含敏感词的 Prompt
- 拒绝包含注入攻击的 Prompt

#### 扩展思路

1）**智能敏感词检﻿测**：接入**阿里云内容安全服务**或**调﻿用专门的 AI 大模型**进行敏感‎词检测，相比静态关键词匹配，能⁠够识别更复杂的语义攻击和隐晦表‍达，提升检测准确率和覆盖面。

2）**动态配置管理**﻿：集成 Nacos 配置中心实﻿现敏感词库的动态维护，支持热更‎新敏感词规则，无需重启服务。管⁠理员可以通过配置中心实时调整检‍测策略，快速响应新的攻击模式。

3）**Prompt 重写**﻿：利用护轨机制实现 Prompt 的重写功﻿能，当检测到潜在风险内容时，自动移除或替换‎敏感信息（顺便优化 Prompt 的专业性⁠、或者防止超出大模型的能力），而不是直接拒‍绝请求，在保证安全的同时提升用户体验。

4）**定制化﻿错误反馈**：优化后端﻿异常处理器逻辑，捕‎获护轨异常并通过 ⁠SSE 向前端推送‍准确的错误信息。

5）**审查记录**﻿：通过日志或数据库记录﻿所有拦截事件的详细信息‎，包括触发规则、用户信⁠息、处理结果等，便于我‍们持续优化系统安全性。



### 4、稳定性优化

#### 重试策略 - 输出护轨

由于大模型调用存在不确定性，有时候可能返回不符合预期的内容、或者回复中断。所以为了提升系统的稳定性，外面需要让大模型调用失败时能够自动重试，并且还可以实现自定义的重试策略，在 AI 响应内容不符合要求时也自动重试。

##### LangChain4j 重试机制

其实 LangChain4j 的 ChatModel 对象本身就支持重试，可以通过配置 `max-retries` 参数修改重试次数（默认值是 2），构造 ChatModel 时也可以设置重试次数，如果想自己决定重试时机和策略，可以利用 [LangChain4j 的输出护轨](https://docs.langchain4j.dev/tutorials/guardrails#output-guardrail-outcomes)，可以对 AI 的响应结果进行检测和处理，并且提供了多种结果类型

其中最有用的几种是：

- `success()`：允许响应通过
- `retry()`：使用相同的输入重新调用 AI
- `reprompt()`：添加额外的提示信息后重新调用 AI
- `fatal()`：中断 AI 响应，抛出异常

经过测试，如果用了输出护轨，可能会导致流式输出的响应不及时，等到 AI 输出结束才一起返回，所以如果为了追求流式输出效果，建议不要通过护轨的方式进行重试。



#### 工具调用优化

##### 方案1- 设置调用工具次数上限

```java
AiServices.builder(AiCodeGeneratorService.class)
    .maxSequentialToolsInvocations(20)  // 最多连续调用 20 次工具
    .build();
```



##### 方案2 - 提供退出工具

还可以为 AI 提供一个专门的退出工具，让它能够主动结束工具调用循环。在 `ai.tools` 包下新建一个继承了 BaseTool 的工具类，这样可以被 ToolManager 自动注册。

这种方案的优﻿势在于给了 AI 更多的主动﻿权。AI 可以根据任‎务完成情况主动判断是否需⁠要继续调用工具，而不是被‍动地等待达到调用次数上限。

💡注意：退出工具的效﻿果其实在自主实现的多步骤智能体中效果更﻿好。所以我建议如果你的应用中很‎少出现工具调用循环的问题，可以只使用方⁠案 1。因为每多一个工具都会增‍加系统的复杂性和不稳定性。



### 5、成本优化

#### AI 大模型成本控制

在实际运营中， AI 大模型的调用成本是一种不可忽视的因素。不同模型的定价差异很大，我们需要根据不同的使用场景选择合适的模型。

##### 成本分析

不同模型之间的成本差异是非常显著的。对于智能路由这种相对简单的分类任务，我们完全可以使用成本更低的模型。



### 扩展思路

1）**AI 响应缓存**﻿：对主页示例 Prompt 的输出﻿、智能路由结果等进行缓存。可以直接‎用字符串匹配，还可以通过相似度算法⁠匹配用户输入，复用已有结果，大幅减‍少 AI 调用次数和成本。

2）**用户用量统计﻿与分析**：实现详细的用量统计系统﻿，记录每个用户的 AI 调用次‎数、Token 消耗量、生成应⁠用数量等指标，实现精细化成本控‍制。（本项目后续会带大家实现）

3）**存储成本优化**：﻿定期清理 COS 对象存储中长期未访﻿问的应用文件和临时构建产物，或者根据‎访问频率和时间自动迁移文件，降低存⁠储成本。

4）**流量成﻿本控制**：优化 AP﻿I 和 SSE 响‎应数据结构，减少不⁠必要的字段返回，压‍缩响应体积，从而减少流量
